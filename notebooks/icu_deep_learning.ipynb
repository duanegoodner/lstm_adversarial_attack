{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# ICU Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prior to Using this Notebook\n",
    "\n",
    "- Review the [ICU Deep Learning project README](https://github.com/duanegoodner/icu-deep-learning/tree/main)\n",
    "- Follow instructions in [SETUP.md](https://github.com/duanegoodner/icu-deep-learning/blob/main/SETUP.md) for setting up and and running the necessary Docker containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Structure\n",
    "\n",
    "Although this project does not include standard package metadata files (e.g., `pyproject.toml`), the code under `./src/` is organized as a top-level package, **`lstm_adversarial_attack`**, with the following sub-packages:  \n",
    "- **`query_db`** â€“ Manages interactions with the MIMIC-III PostgreSQL database.  \n",
    "- **`tuning_db`** â€“ Handles PostgreSQL databases used for **Optuna** hyperparameter tuning.  \n",
    "- **`preprocess`** â€“ Converts **SQL query output** into numerical arrays used as model inputs and targets.  \n",
    "- **`dataset`** â€“ Wraps preprocessed arrays into **PyTorch Dataset** objects for use in LSTM models.  \n",
    "- **`model`** â€“ Conducts **hyperparameter tuning, training, and evaluation** of predictive models.  \n",
    "- **`attack`** â€“ Tunes and trains an **adversarial attack model** on a subset of data, then uses it to attack the full dataset.  \n",
    "- **`attack_analysis`** â€“ Organizes and analyzes adversarial attack results, characterizing distributions of discovered adversarial examples.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Start: Running from the Command Line\n",
    "\n",
    "This section provides **minimal** instructions for running the full project pipeline **from the command line** with default settings. It is intended for users who want to execute all steps **as quickly as possible** inside the `lstm_aa_app` container.\n",
    "\n",
    "For **detailed explanations** of each step, including intermediate analysis and discussion, refer to **subsequent sections** of this notebook, where each step is explored in depth.\n",
    "\n",
    "\n",
    "\n",
    "## 3.1 Pre-requisites\n",
    "\n",
    "Before proceeding, ensure that:\n",
    "\n",
    "âœ… You have completed Steps 1â€“6 in SETUP.md.\n",
    "\n",
    "âœ… You are running a shell inside the lstm_aa_app container.\n",
    "\n",
    "If you're unsure, refer to [SETUP.md](https://github.com/duanegoodner/icu-deep-learning/blob/main/SETUP.md) for instructions on running and entering.\n",
    "\n",
    "## 3.2 Running the Full Pipeline with Default Settings  \n",
    "\n",
    "From a command prompt running inside the container, navigate to:\n",
    "\n",
    " ```\n",
    " /home/devspace/project/src/lstm_adversarial_attack\n",
    " ```\n",
    " Then, run the commands shown in the table below. These commands execute all steps in the project pipeline using **default parameters**.  The output paths are relative to `/home/devspace/project/data/` which is mapped by **docker compose** to `./data/` in the local `icu-deep-learning` repository. \n",
    "\n",
    "| Step | Command                             | Effects                                                                                     | Output Dir  |\n",
    "|------|-------------------------------------|---------------------------------------------------------------------------------------------|--------------------------|\n",
    "| 1    | `python -m query_db`                | Runs all MIMIC-III PostgreSQL queries and saves output as **.csv** files.                   | `query_db/`             |\n",
    "| 2    | `python -m preprocess`              | Converts database query output into arrays for LSTM model inputs<br>and prediction targets. Saves at **5 intermediate steps**. | `preprocess/`           |\n",
    "| 3    | `python model/tune_new.py`          | Performs **hyperparameter tuning** for the LSTM predictive model.                           | `model/tuning/`         |\n",
    "| 4    | `python model/train.py`        | Trains and tests the LSTM model using **selected hyperparameters**.                         | `model/cross_validation/` |\n",
    "| 5    | `python attack/tune_attack_new.py`  | Tunes attack model hyperparameters for adversarial attacks on a **trained predictive model**. | `attack/tuning/`       |\n",
    "| 6    | `python attack/attack.py`           | Runs **adversarial attacks** using the tuned attacker.                                      | `attack/frozen_hyperparameter_attack/` |\n",
    "| 7    | `python -m attack_analysis`         | Analyzes and plots results of adversarial attacks.                                          | `attack/attack_analysis/` |\n",
    "\n",
    "\n",
    "## 3.3 Reviewing Results  \n",
    "\n",
    "After running the pipeline, plots characterizing the discovered **adversarial examples** can be found in:  \n",
    "\n",
    "ðŸ“‚ `./data/attack/attack_analysis/`  \n",
    "\n",
    "These plots provide detailed characteristics of **attack results** but do **not** include information on the preceding pipeline stages (e.g., model training, preprocessing). For further details on those steps, refer to the respective sections later in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. Running Code from within this Notebook\n",
    "\n",
    "### 4.1 Pre-requisites\n",
    "\n",
    "The remainder of this notebook contains code cells for running the project in a connected IPython interpreter. Before proceeding, ensure that:\n",
    "\n",
    "âœ… You have completed Steps 1â€“7 in [SETUP.md](https://github.com/duanegoodner/icu-deep-learning/blob/main/SETUP.md).\n",
    "\n",
    "âœ… This notebook is connected to a Jupyter server instance running inside Docker container `lstm_aa_app`.\n",
    "\n",
    "If you're unsure, refer to [SETUP.md](https://github.com/duanegoodner/icu-deep-learning/blob/main/SETUP.md) for instructions on how to run Jupyter inside the container.\n",
    "\n",
    "\n",
    "\n",
    "### 4.2 Check the Python Interpreter and IPython Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devspace/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "# Output should be: /home/devspace/env/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gen_user/.local/share/jupyter/runtime/kernel-v3e244e5730daa0cada4896ee8ab05ebfc2f09f5c0.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "get_ipython().kernel.config[\"IPKernelApp\"][\"connection_file\"]\n",
    "# Outptut should be similar to: '/home/gen_user/.local/share/jupyter/runtime/kernel-v2-26202uI0Vk7x2nHkK.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test Database Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to test the MIMIC-III database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MIMIC-III database.\n",
      "Connection to MIMIC-III database successfully closed.\n"
     ]
    }
   ],
   "source": [
    "!python /home/devspace/project/src/lstm_adversarial_attack/query_db/test_mimiciii_db.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run test queries on the databases that will handle hyperparameter tuning data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_tuning database successfully queried.\n",
      "Found 2 tuning studies.\n",
      "attack_tuning database successfully queried.\n",
      "Found 3 tuning studies.\n"
     ]
    }
   ],
   "source": [
    "!python /home/devspace/project/src/lstm_adversarial_attack/tuning_db/test_tuning_study_dbs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check for GPU\n",
    "\n",
    "The PyTorch code in our project will run much faster on a GPU than it will on a CPU. Let's find out if we have GPU access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Change Working Directory\n",
    "Many of the code cells in this notebook use relative paths and assume we are in directory `/home/devspace/project/src/lstm_adversarial_attack`, so let's change to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devspace/project/src/lstm_adversarial_attack\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/devspace/project/src/lstm_adversarial_attack\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Project Structure\n",
    "Our `docker-compose.yml` maps the local project root directory to `/home/devspace/project` in the container. Run the following cell for an overview of our project layout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;32mREADME.md\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;32mSETUP.md\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;32mconfig.toml\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mdata\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mdocker\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mdocs\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mlogs\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mnotebooks\u001b[0m\n",
      "â””â”€â”€ \u001b[01;34msrc\u001b[0m\n",
      "\n",
      "6 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "!tree -L 1 /home/devspace/project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 `src/`\n",
    "The contents of `/home/devspace/project/src/lstm_adversarial_attack` are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project/src/lstm_adversarial_attack\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34m__pycache__\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mattack\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mattack_analysis\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mconfig\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mdataset\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mmodel\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mpreprocess\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mquery_db\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mtuning_db\u001b[0m\n",
      "â””â”€â”€ \u001b[01;34mutils\u001b[0m\n",
      "\n",
      "10 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 1 /home/devspace/project/src/lstm_adversarial_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Code in the sub-directories listed above forms our project pipeline: \n",
    " * **query_db** runs .sql queries to extract patient lab, vital sign, and in-hospital mortality data from the MIMIC-III PostgreSQL database.\n",
    " * **preprocess** transforms .sql query output into a form that can be input to PyTorch models. \n",
    " * **model** tunes and trains a PyTorch model for predicting in-hospital mortality based on lab and vital sign time-series data.\n",
    " * **attack** tunes and trains a PyTorch attack model that generates adversarial examples for the predictive model.\n",
    " * **attack_analysis** generates plots for visualizing characteristics of adversarial examples found by the attack model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `config.toml`\n",
    "Project configuration variables are set in the `config.toml` file. We can use the `get_config_value` and `set_config_value` from `utils.notebook_helpers` to read and write to the `config.toml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_config_value in module utils.notebook_helpers:\n",
      "\n",
      "get_config_value(config_key: str) -> str\n",
      "    Gets value from config.toml\n",
      "    :param config_key: config.toml key as dotted string\n",
      "    :return: value corresponding to config.toml key\n",
      "\n",
      "Help on function set_config_value in module utils.notebook_helpers:\n",
      "\n",
      "set_config_value(config_key: str, value: Any)\n",
      "    Sets value from config.toml\n",
      "    :param config_key: config.toml key as dotted string\n",
      "    :param value: value to assign to key\n",
      "    :return: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import utils.notebook_helpers as nh\n",
    "\n",
    "help(nh.get_config_value)\n",
    "help(nh.set_config_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick example of reading and writing to `config.toml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: 1234\n",
      "Value changed to: 2024\n",
      "Final value: 1234\n"
     ]
    }
   ],
   "source": [
    "orig_kfold_random_seed = nh.get_config_value(\"model.tuner_driver.kfold_random_seed\")\n",
    "print(f\"Original value: {orig_kfold_random_seed}\")\n",
    "\n",
    "nh.set_config_value(\"model.tuner_driver.kfold_random_seed\", 2024)\n",
    "modified_kfold_random_seed = nh.get_config_value(\"model.tuner_driver.kfold_random_seed\")\n",
    "print(f\"Value changed to: {modified_kfold_random_seed}\")\n",
    "\n",
    "nh.set_config_value(\"model.tuner_driver.kfold_random_seed\", orig_kfold_random_seed)\n",
    "\n",
    "final_kfold_random_seed = nh.get_config_value(\"model.tuner_driver.kfold_random_seed\")\n",
    "print(f\"Final value: {final_kfold_random_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 `data/`\n",
    "\n",
    "For each of the critical directories under `src/lstm_adversarial_attack/`, there is a corresponding directory under `data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project/data\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mattack\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mattack_analysis\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mmodel\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34mpreprocess\u001b[0m\n",
      "â””â”€â”€ \u001b[01;34mquery_db\u001b[0m\n",
      "\n",
      "5 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree -L 1 /home/devspace/project/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subdirectories under `/data` contain output from runs of a particular data-generating sub-package or module. Example contents of `data/query_db` are shown below. There are data from three runs, with each containing `.csv` query result files as well as `.toml` files capturing the project configuration settings at the time of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project/data/query_db\u001b[0m\n",
      "â”œâ”€â”€ \u001b[01;34m20250222210125577048\u001b[0m\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;34mconfigs\u001b[0m\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;32msession_config.toml\u001b[0m\n",
      "â”‚Â Â  â”‚Â Â  â””â”€â”€ \u001b[01;32msession_config_paths.toml\u001b[0m\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;32micustay_detail.csv\u001b[0m\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;32mpivoted_bg.csv\u001b[0m\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;32mpivoted_lab.csv\u001b[0m\n",
      "â”‚Â Â  â””â”€â”€ \u001b[01;32mpivoted_vital.csv\u001b[0m\n",
      "â””â”€â”€ \u001b[01;34m20250223131513840062\u001b[0m\n",
      "    â”œâ”€â”€ \u001b[01;34mconfigs\u001b[0m\n",
      "    â”‚Â Â  â”œâ”€â”€ \u001b[01;32msession_config.toml\u001b[0m\n",
      "    â”‚Â Â  â””â”€â”€ \u001b[01;32msession_config_paths.toml\u001b[0m\n",
      "    â”œâ”€â”€ \u001b[01;32micustay_detail.csv\u001b[0m\n",
      "    â”œâ”€â”€ \u001b[01;32mpivoted_bg.csv\u001b[0m\n",
      "    â”œâ”€â”€ \u001b[01;32mpivoted_lab.csv\u001b[0m\n",
      "    â””â”€â”€ \u001b[01;32mpivoted_vital.csv\u001b[0m\n",
      "\n",
      "4 directories, 12 files\n"
     ]
    }
   ],
   "source": [
    "!tree /home/devspace/project/data/query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Keeping Track of the Data Pipeline when Running in a Notebook\n",
    "We will use an instance of `notebook_helpers.PipelineInfo` to store and retrieve module and sub-package runs' metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PipelineInfo in module utils.notebook_helpers:\n",
      "\n",
      "class PipelineInfo(builtins.object)\n",
      " |  PipelineInfo(sessions: dict[str, utils.notebook_helpers.SessionInfo] = None, next_session_index: int = 1)\n",
      " |  \n",
      " |  Container metadata of data-generating sessions. Intended for use in Jupyter\n",
      " |   notebooks.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sessions: dict[str, utils.notebook_helpers.SessionInfo] = None, next_session_index: int = 1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_stored_session(self, session_type: utils.notebook_helpers.SessionType, session_id: str | int = None) -> utils.notebook_helpers.SessionInfo\n",
      " |      Gets info on a stored session. If PipelineInfo object has more than one\n",
      " |      entry for session of session_type, must specify session ID.\n",
      " |      :param session_type: Type of session to retrieve\n",
      " |      :param session_id: ID of session\n",
      " |      :return: info for session\n",
      " |  \n",
      " |  store_session(self, session_type: utils.notebook_helpers.SessionType, session_id: str | int = None, comment: str = None)\n",
      " |      Stores info for a data generating session\n",
      " |      :param session_type: type of session\n",
      " |      :param session_id: ID of session\n",
      " |      :param comment: optional comment\n",
      " |      :return: None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nh.PipelineInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will instantiate an empty PipelineInfo object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pipeline_info = nh.PipelineInfo()\n",
    "pprint.pprint(pipeline_info.sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we run any data-generating code, we will store metadata in our PipelineInfo object. Note that we can also use the `store_session` method to store metadata to a data-generating run performed outside of our notebook session. This outside run could have been initiated from the command line, or from an ealier notebook session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Database Queries\n",
    "\n",
    "Raw ICU patient data can be extracted from the MIMIC-III database using modified versions of four `.sql`queries from the [MIT-LCP mimic-code repository](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts/pivot).\n",
    "\n",
    "### 4.1 Running the Queries\n",
    "\n",
    "We connect to the database and execute the queries by running the [\\_\\_main__](../src/lstm_adversarial_attack/query_db/__main__.py) module of the [query_db](../src/lstm_adversarial_attack/query_db/\\_\\_init__.py) sub-package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [-q [QUERY_DIR]]\n",
      "\n",
      "Runs .sql queries on MIMIC-III database\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -q [QUERY_DIR], --query_dir [QUERY_DIR]\n",
      "                        Directory containing .sql query files. Defaults to\n",
      "                        path specified by paths.db.output_root in config.toml\n"
     ]
    }
   ],
   "source": [
    "!python -m query_db --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query session: 20250223131513840062\n",
      "\n",
      "Query 1 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/icustay_detail.sql\n",
      "Done. Query time = 0.25 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20250223131513840062/icustay_detail.csv\n",
      "Done. csv write time = 0.18 seconds\n",
      "\n",
      "Query 2 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_bg.sql\n",
      "Done. Query time = 8.50 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20250223131513840062/pivoted_bg.csv\n",
      "Done. csv write time = 1.46 seconds\n",
      "\n",
      "Query 3 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_lab.sql\n",
      "Done. Query time = 10.67 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20250223131513840062/pivoted_lab.csv\n",
      "Done. csv write time = 2.41 seconds\n",
      "\n",
      "Query 4 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_vital.sql\n",
      "Done. Query time = 38.00 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20250223131513840062/pivoted_vital.csv\n",
      "Done. csv write time = 10.22 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Storing Query Session Info\n",
    "We can register the most recently created query session in our `PipelineInfo` storage container using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250223131513840062 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type = nh.SessionType.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20250223131513840062': SessionInfo(session_type=<SessionType.DB_QUERIES: 1>,\n",
      "                                     session_id='20250223131513840062',\n",
      "                                     comment=None)}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(pipeline_info.sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Implementation Details\n",
    "\n",
    "We will use the [`preprocess`](../src/lstm_adversarial_attack/preprocess/__init__.py) sub-package to transform information from the `.csv` files output by the `.sql` queries into numpy arrays (which can then be easily converted into PyTorch tensors). Running this sub-package instantiates a `Preprocessor` object with a `.preprocess_modules` attribute assigned by the following code in  [`preprocessor.py`](../src/lstm_adversarial_attack/preprocess/preprocessor.py):\n",
    "\n",
    "```\n",
    "self.preprocess_modules = [\n",
    "            prf.Prefilter(),\n",
    "            imc.ICUStayMeasurementCombiner(),\n",
    "            slb.FullAdmissionListBuilder(),\n",
    "            fb.FeatureBuilder(),\n",
    "            ff.FeatureFinalizer(),\n",
    "        ]\n",
    "```\n",
    "Each element of the `.preprocess_modules` attribute is a subclass of [`PreprocessModule`](../src/lstm_adversarial_attack/preprocess/preprocess_module.py).\n",
    "\n",
    "* [`Prefilter`](../src/lstm_adversarial_attack/preprocess/prefilter.py) reads the database query outputs into Pandas Dataframes, removes all data related to patients younger than 18 years in age, ensures consistent column naming formats, and takes care of datatype details.\n",
    "* [`ICUStayMeasurementCombiner`](../src/lstm_adversarial_attack/preprocess/icustay_measurement_combiner.py) performs various joins (aka \"merges\" in the language of Pandas) to combine lab and vital sign measurement data with ICU stay data.\n",
    "* [`FullAdmissionListBuilder`](../src/lstm_adversarial_attack/preprocess/sample_list_builder.py) generates a list consisting of one FullAdmissionData object per ICU stay. The attributes of a FullAdmissionData object include ICU stay info, and a dataframe containing the measurement and timestamp data for all vital sign and lab data associated with the ICU stay.\n",
    "* [`FeatureBuilder`](../src/lstm_adversarial_attack/preprocess/feature_builder.py) resamples the time series datafame to one-hour intervals, imputes missing data, winsorizes measurement values (with cutoffs at the 5th and 95th global percentiles), and normalizes the measuremnt values so all data are between 0 and 1.\n",
    "* [`FeatureFinalizer`](../src/lstm_adversarial_attack/preprocess/feature_finalizer.py) selects the data observation time window (default starts at hospital admission time and ends 48 hours after admission). This module outputs the entire dataset features as a list of numpy arrays, and the mortality labels as a list of integers. These data structures (saved as .pickle files) will be convenient starting points when the `tune_train` and `attack` sub-packages need to create PyTorch Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Set Preprocess Config Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"preprocess\", {'min_age': 18,\n",
    " 'min_los_hospital': 1,\n",
    " 'min_los_icu': 1,\n",
    " 'bg_data_cols': ['potassium', 'calcium', 'ph', 'pco2', 'lactate'],\n",
    " 'lab_data_cols': ['albumin',\n",
    "  'bun',\n",
    "  'creatinine',\n",
    "  'sodium',\n",
    "  'bicarbonate',\n",
    "  'platelet',\n",
    "  'glucose',\n",
    "  'magnesium'],\n",
    " 'vital_data_cols': ['heartrate',\n",
    "  'sysbp',\n",
    "  'diasbp',\n",
    "  'tempc',\n",
    "  'resprate',\n",
    "  'spo2'],\n",
    " 'winsorize_low': '5%',\n",
    " 'winsorize_high': '95%',\n",
    " 'resample_interpolation_method': 'linear',\n",
    " 'resample_limit_direction': 'both',\n",
    " 'min_observation_hours': 48,\n",
    " 'observation_window_hours': 48,\n",
    " 'observation_window_start': 'intime'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Run the Preprocess Modules\n",
    "\n",
    "We can run all preprocessing modules by executing the `preprocess` sub-packages `__main__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [-d [DB_RESULT_ID]]\n",
      "\n",
      "Takes data output from database query, and runs through preprocess modules.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -d [DB_RESULT_ID], --db_result_id [DB_RESULT_ID]\n",
      "                        ID of database query session to take output from.\n",
      "                        Defaults to latest query.\n"
     ]
    }
   ],
   "source": [
    "!python -m preprocess --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20250223131513840062 \n"
     ]
    }
   ],
   "source": [
    "db_queries_session = pipeline_info.get_stored_session(session_type=nh.SessionType.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess session will use data from database query session 20250223131513840062\n",
      "Starting preprocess session 20250223131653849429\n",
      "\n",
      "Running Prefilter\n",
      "Prefilter init time = 5.918374300003052\n",
      "Prefilter process time = 1.6608531475067139\n",
      "Prefilter export time = 0.3108096122741699\n",
      "Output saved in /home/devspace/project/data/preprocess/20250223131653849429/1_prefilter\n",
      "\n",
      "Running ICUStayMeasurementMerger\n",
      "ICUStayMeasurementMerger init time = 0.01996326446533203\n",
      "ICUStayMeasurementMerger process time = 14.454586029052734\n",
      "ICUStayMeasurementMerger export time = 1.337817668914795\n",
      "Output saved in /home/devspace/project/data/preprocess/20250223131653849429/2_merged_stay_measurements\n",
      "\n",
      "Running AdmissionListBuilder\n",
      "AdmissionListBuilder init time = 0.0076215267181396484\n",
      "AdmissionListBuilder process time = 19.395607233047485\n",
      "AdmissionListBuilder export time = 17.45841383934021\n",
      "Output saved in /home/devspace/project/data/preprocess/20250223131653849429/3_full_admission_list\n",
      "\n",
      "Running FeatureBuilder\n",
      "FeatureBuilder init time = 0.007745027542114258\n",
      "Done building features for sample 5000/41960\n",
      "Done building features for sample 10000/41960\n",
      "Done building features for sample 15000/41960\n",
      "Done building features for sample 20000/41960\n",
      "Done building features for sample 25000/41960\n",
      "Done building features for sample 30000/41960\n",
      "Done building features for sample 35000/41960\n",
      "Done building features for sample 40000/41960\n",
      "FeatureBuilder process time = 138.51208972930908\n",
      "FeatureBuilder export time = 24.928189039230347\n",
      "Output saved in /home/devspace/project/data/preprocess/20250223131653849429/4_feature_builder\n",
      "\n",
      "Running FeatureFinalizer\n",
      "FeatureFinalizer init time = 0.0038330554962158203\n",
      "Received 41960 samples.\n",
      "Sending 37832 samples to final output.\n",
      "FeatureFinalizer process time = 11.578262090682983\n",
      "FeatureFinalizer export time = 1.2560234069824219\n",
      "Output saved in /home/devspace/project/data/preprocess/20250223131653849429/5_feature_finalizer\n",
      "\n",
      "Total preprocess time = 236.8536398410797\n"
     ]
    }
   ],
   "source": [
    "!python -m preprocess -d {db_queries_session.session_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250223131653849429 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type=nh.SessionType.PREPROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20250223131513840062': SessionInfo(session_type=<SessionType.DB_QUERIES: 1>,\n",
      "                                     session_id='20250223131513840062',\n",
      "                                     comment=None),\n",
      " '20250223131653849429': SessionInfo(session_type=<SessionType.PREPROCESS: 2>,\n",
      "                                     session_id='20250223131653849429',\n",
      "                                     comment=None)}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(pipeline_info.sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Summarize Feature Finalizer Output\n",
    "We can get information about the array shape and value distributions of the preprocessed using the `preprocess` sub-package's `inspect_feature_finalizer` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: inspect_feature_finalizer_output.py [-h] [-p [PREPROCESS_ID]]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -p [PREPROCESS_ID], --preprocess_id [PREPROCESS_ID]\n",
      "                        ID of preprocess session to use as data source.\n",
      "                        Defaults to latest session\n"
     ]
    }
   ],
   "source": [
    "!python preprocess/inspect_feature_finalizer_output.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20250223131653849429 \n"
     ]
    }
   ],
   "source": [
    "preprocess_session = pipeline_info.get_stored_session(session_type=nh.SessionType.PREPROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of output from preprocess session 20250223131653849429\n",
      "\n",
      "Number of samples = 37832\n",
      "\n",
      "Time Series Sequence Length Distribution\n",
      "----------------------------------------\n",
      "sequence_length     48\n",
      "count            37832\n",
      "\n",
      "Measurement Column Counts Distribution\n",
      "--------------------------------------\n",
      "num_measurements     19\n",
      "count             37832\n",
      "\n",
      "Min value of any element in any feature matrix = 0.0\n",
      "Max value of any element in any feature matrix = 1.0\n",
      "\n",
      "Class Labels Distribution\n",
      "-------------------------\n",
      "class_label      0     1\n",
      "count        33991  3841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python preprocess/inspect_feature_finalizer_output.py -p {preprocess_session.session_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in the FeatureFinalizer output is from a unique ICU stay, and consists of a 2D matrix of input features and a binary class label. Each column in a feature matrix corresponds to a particular lab or vital sign measurement, and each row in a feature matrix corresponds to the number of hours elapsed after a patient's hospital admission time. A class label of 1 indicates an in-hospital mortality event.\n",
    "\n",
    "When preprocessor parameters in `config.toml` are set to default values, the FeatureFinalizer output consists of 37832 samples, and the shape of all input feature arrays is 48 x 19, and approximately 11% of the preprocessed samples have class label = 1. Later, when we tune and train our predictive model, we will use oversampling techniques to deal with the significant class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Preprocessing Time\n",
    "\n",
    "On an Intel i7-13700K CPU, the above preprocessing work takes approximately 3.9 minutes. Achieving the same transformations on the same machine with preprocessing code from [[1](#References)] takes approximately 45 minutes. This time difference is largely due to the fact that the current project preprocess subpackage avoids using  unnecessary loops and relies heavily vectorized Pandas and Numpy operations.\n",
    "\n",
    "Additional time reduction could be achieved by parellelizing the preprocess computations with tools such as [pandaparallel](https://github.com/nalepae/pandarallel) or [pyspark](https://spark.apache.org/docs/3.3.1/api/python/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "\n",
    "The starting point for our predictive model is based on the model in [1] and consists of the following layers:\n",
    "\n",
    "| Layer # | Description        | Input Shape                            | Parameters          | Output Shape           | Activation       |\n",
    "| ------- | ------------------ | -------------------------------------- | ------------------- | ---------------------- | ---------------- |\n",
    "| 1       | Bidirectional LSTM | (b, t<sub>max</sub> = 48, n<sub>meas</sub> = 19) | n<sub>LSTM</sub>    | (b, 2n<sub>LSTM</sub>) | a<sub>LSTM</sub> |\n",
    "| 2       | Dropoout           | (b, 2n<sub>LSTM</sub>)                 | P<sub>dropout</sub> | (b, 2n<sub>LSTM</sub>) | -                |\n",
    "| 3       | Fully Connected    | (b, 2n<sub>LSTM</sub>)                 | n<sub>FC</sub>      | (b, n<sub>FC</sub>)    | a<sub>FC</sub>   |\n",
    "| 4       | Output             | (b, n<sub>FC</sub>)                    | n<sub>out</sub> = 2 | (b, n<sub>out</sub>    | a<sub>out</sub>  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters from the above table are defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter           | Description                                             |\n",
    "| ------------------- | ------------------------------------------------------- |\n",
    "| b                   | Batch size                                              |\n",
    "| t<sub>max</sub>     | Maximum input sequence length                           |\n",
    "| n<sub>meas</sub>    | Number of patient measurement types                     |\n",
    "| n<sub>LSTM</sub>    | Number of features in a LSTM hidden state               |\n",
    "| a<sub>LSTM</sub>    | Activation function for the LSTM output                 |\n",
    "| P<sub>dropout</sub> | Dropout probablity                                      |\n",
    "| n<sub>FC</sub>      | Numbef of nodes in the fully connected layer            |\n",
    "| a<sub>FC</sub>      | Activation function for the fully connected layer ouput |\n",
    "| n<sub>out</sub>     | Number of nodes in the output layer                     |\n",
    "| a<sub>out</sub>     | Activation function for the output layer                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that n<sub>meas</sub>, n<sub>out</sub>, abd s<sub>max</sub> are fixed. We have chosen to always use all 19 patient measurement types, and our classification problem always has two classes. In our current data pipeline, data collected outside of a specified time window are removed during the final preprocessing phase. If we want the observation window to be tunable, it would be helpful to move the `preprocess.feature_finalizer` module into the `tune_attack` sub-package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Hyperparameter Tuning\n",
    "\n",
    "### 7.1 Architectural hyperparameters\n",
    "\n",
    "The following table lists the ranges architectural parameters to be explored during hyperparameter tuning.\n",
    "\n",
    "| Parameter           | Tuning Type  | Values                            |\n",
    "| ------------------- | ------------ | --------------------------------- |\n",
    "| b                   | Discrete     | 2<sup>k</sup> , k = 5, 6, 7, 8    |                    \n",
    "| h<sub>LSTM</sub>    | Discrete     | 2<sup>k</sup> , k = 5, 6, 7       |\n",
    "| a<sub>LSTM</sub>    | Discrete     | ReLU, Tanh                        |\n",
    "| P<sub>dropout</sub> | Continuous   | 0.000 &mdash; 0.5000        |\n",
    "| h<sub>FC</sub>      | Discrete     | 2<sup>k</sup> , k = 4, 5, 6, 7, 8 |\n",
    "| a<sub>FC</sub>      | Discrete     | ReLU, Tanh                        |\n",
    "\n",
    "\n",
    "### 7.2 Trainer hyperparameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During hyperparameter tuning, we also explore different training optimization algorithms and learning rates.\n",
    "\n",
    "| Parameter     | Tuning Type | Values             |\n",
    "| ------------- | ----------- | ------------------ |\n",
    "| Optimizer     | Discrete    | SGD, RMSprop, Adam |\n",
    "| Learning Rate | Continuous  | 1e-5 - 1e-1        |\n",
    "\n",
    "When using the Adam optimizer, we always use the Pytorch default values of $\\beta_1 = 0.9, \\beta_2 = 0.999, \\epsilon = 10^{-8}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Implementation Details\n",
    "The [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py) class in the [`model`](../src/lstm_adversarial_attack/model/__init__.py) sub-package implements a cross-validation tuning scheme that utilizes the [Optuna](https://optuna.org/) framework. The boundaries of hyperparameter space to explore during tuning are set in the `[model.tuner_driver.tuning_ranges]` section of the projectr `config.toml` file.\n",
    "\n",
    "Other model hyperparameter tuning settings are also configured under `[model.tuner_driver]`. In the standard configuration, a PyTorch [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) generator is used to assign samples to each fold. When selecting samples for each training batch, we use a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) with a [`WeightedRandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler) to oversample from the minority class (label = 1). For a given set of hyperparameters, the [`HyperParameterTuner.objective_fn`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) method returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna [`TPESampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html) to select new sets of hyperparameters for additional trials. [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) also uses an Optuna [`MedianPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html) to stop unpromising trials early.\n",
    "\n",
    "### 7.4 Model Tuning Configuration Settings\n",
    "Set `[model.tuner_driver]` configuration values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"model.tuner_driver\", {'num_trials': 60,\n",
    " 'num_folds': 5,\n",
    " 'num_cv_epochs': 10,\n",
    " 'epochs_per_fold': 5,\n",
    " 'kfold_random_seed': 1234,\n",
    " 'performance_metric': 'validation_loss',\n",
    " 'optimization_direction_label': 'minimize',\n",
    " 'tuning_output_dir': 'data/model/tuning',\n",
    " 'pruner_name': 'MedianPruner',\n",
    " 'sampler_name': 'TPESampler',\n",
    " 'db_env_var_name': 'MODEL_TUNING_DB_NAME',\n",
    " 'fold_class_name': 'StratifiedKFold',\n",
    " 'collate_fn_name': 'x19m_collate_fn',\n",
    " 'cv_mean_tensorboard_metrics': ['accuracy',\n",
    "  'auc',\n",
    "  'f1',\n",
    "  'precision',\n",
    "  'recall',\n",
    "  'validation_loss'],\n",
    " 'tuning_ranges': {'log_lstm_hidden_size': [5, 7],\n",
    "  'lstm_act_options': ['ReLU', 'Tanh'],\n",
    "  'dropout': [0.0, 0.5],\n",
    "  'log_fc_hidden_size': [4, 8],\n",
    "  'fc_act_options': ['ReLU', 'Tanh'],\n",
    "  'optimizer_options': ['Adam', 'RMSprop', 'SGD'],\n",
    "  'learning_rate': [1e-05, 0.1],\n",
    "  'log_batch_size': [5, 8]},\n",
    " 'pruner_kwargs': {'n_startup_trials': 5, 'n_warmup_steps': 3},\n",
    " 'sampler_kwargs': {}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `[model.tuner_driver]` secton of the `config.toml` includes parameters that determine the number of tuning trials, cross-validation folds, and epochs. With the values set above, we run an Optuna study with 60 trials. Each trial uses 5-fold cross-validation, and we run `num_cv_epochs * epochs_per_fold = 10 * 5 = 50` total epochs on each fold. (NOTE: Consider changing tname of `epochs_per_fold` to something less confusing.)\n",
    "\n",
    "### 7.5 Start a New Hyperparameter Tuning Study\n",
    "Before starting, a few things to note:\n",
    "* Depending your GPU compute power, running the full 30 trials could take 2 - 20 hours.\n",
    "* Results will be saved to a newly created directory (with a timestamp-based name) under `data/model/tuning/<tuning_session_id>`. \n",
    "* If the study is stopped early (via CTRL-C or the Jupyter Stop button), learning from whatever trials have completed up to that point will be saved.\n",
    "* While the tuning trials are running, read ahead to the notebook section with instructions on how to monitor progress in Tensorboard.\n",
    "\n",
    "We can start a new hyperparaemter tuning session by running the `tune_new` module in the `model` sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune_new.py [-h] [-p [PREPROCESS_ID]] [-r]\n",
      "\n",
      "Creates and runs a new model hyperparameter tuning study.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -p [PREPROCESS_ID], --preprocess_id [PREPROCESS_ID]\n",
      "                        ID of preprocess session to use as data source.\n",
      "                        Defaults to most recently created preprocess session.\n",
      "  -r, --redirect        Redirect terminal output to log file\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_new.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since terminal output during tuning can be very long, we will use the  `-r` option to redirect output to a log file and keep our notebook tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20250223131653849429 \n"
     ]
    }
   ],
   "source": [
    "preprocess_session_for_tuning_input = pipeline_info.get_stored_session(session_type=nh.SessionType.PREPROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new model hyperparameter tuning session 20250223132531419387\n",
      "\n",
      "To monitor tuning in tensorboard, run the following command in another terminal:\n",
      "tensorboard --logdir=/home/devspace/project/data/model/tuning/20250223132531419387/tensorboard --host=0.0.0.0\n",
      "Then go to http://localhost:6006/ in your browser.\n",
      "\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/model/tuning/20250223132531419387.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/model/tuning/20250223132531419387.log\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_new.py -p {preprocess_session_for_tuning_input.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command will complete once we have run the number of trials specified by `\"model.tuner_driver.num_trials` in our `config.toml`, or we can also stop cell execution early.\n",
    "\n",
    "Next, we store the model tuning session ID in our `PipelineInfo` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250223132531419387 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Resume an Existing Hyperparameter Tuning Study\n",
    "We can run additional trials for an existing study using the `model` sub-package's `tune_resume` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune_resume.py [-h] [-t [MODEL_TUNING_ID]] [-r]\n",
      "\n",
      "Runs additional model hyperparameter tuning trials for an existing tuning\n",
      "study. Uses previously saved ModelTunerDriver and optuna.Study as starting\n",
      "points. New trial results are added to the existing Study.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [MODEL_TUNING_ID], --model_tuning_id [MODEL_TUNING_ID]\n",
      "                        ID of model tuning session to resume. Defaults to ID\n",
      "                        of most recently created session.\n",
      "  -r, --redirect        Redirect terminal output to log file\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_resume.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to continue a study, we can un-comment each of the next two cells, and assign a value to `model_tuning_id_for_continuation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20250223132531419387 \n"
     ]
    }
   ],
   "source": [
    "model_tuning_session_to_continue = pipeline_info.get_stored_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing existing model hyperparameter tuning session 20250223132531419387\n",
      "To monitor tuning in tensorboard, run the following command in another terminal:\n",
      "tensorboard --logdir=/home/devspace/project/data/model/tuning/20250223132531419387/tensorboard --host=0.0.0.0' in a different terminal\n",
      "Then go to http://localhost:6006/ in your browser.\n",
      "\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/model/tuning/20250223132531419387.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/model/tuning/20250223132531419387.log\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_resume.py -t {model_tuning_session_to_continue.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 Monitor Tuning Progress with Tensorboard\n",
    "\n",
    "While we are tuning hyperparameters, we can monitor results in Tensorboard. Use Jupyter Lab to open a new terminal, and run:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/home/devspace/project/data/model/tuning/<tuning-session-id>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "\n",
    "Then, in your browser, go to: `http://localhost:6006/`. You should see something like the screenshot below.  The x-axis for all plots is epoch number. (Unfortunately, there is no good way to add axis labels in Tensorboard.) Note: `<tuning-session-ID>` is included in the output when running the `tune_new` and/or `tune_resume` modules.\n",
    "\n",
    "Here is an example screen-shot of plots displayed in Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard_image](images/tensorboard_model_tuning_50_epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.9 Review Hyperparameters and Objective Function Scores from Model Tuning Study Trial(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: view_model_hyperparameters.py [-h] [-t [MODEL_TUNING_ID]]\n",
      "                                     [--model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER]\n",
      "\n",
      "Retrieves and displays hyperparameters tested during a model tuning session.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [MODEL_TUNING_ID], --model_tuning_id [MODEL_TUNING_ID]\n",
      "                        ID of model tuning session. Defaults to most recently\n",
      "                        created session.\n",
      "  --model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER, -n MODEL_TUNING_TRIAL_NUMBER\n",
      "                        Optional integer specifying trial number (within\n",
      "                        study).Defaults to best trial from study.\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_hyperparameters.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20250223132531419387 \n"
     ]
    }
   ],
   "source": [
    "model_tuning_session_to_review = pipeline_info.get_stored_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of model tuning session 20250223132531419387, trial number 0:\n",
      "Objective function value = 0.4108834130882461\n",
      "Hyperparameters = \n",
      "{'dropout': 0.040370800817631836,\n",
      " 'fc_act_name': 'ReLU',\n",
      " 'learning_rate': 0.0007766753211242147,\n",
      " 'log_batch_size': 5,\n",
      " 'log_fc_hidden_size': 7,\n",
      " 'log_lstm_hidden_size': 7,\n",
      " 'lstm_act_name': 'Tanh',\n",
      " 'optimizer_name': 'RMSprop'}\n",
      "\n",
      "The best trial from tuning session 20250223132531419387:\n",
      "Trial number 0 with objective function value = 0.4108834130882461\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_hyperparameters.py -t {model_tuning_session_to_review.session_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to view information from a trial other than the best trial from the study, we can specify the trial number to review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of model tuning session 20250223132531419387, trial number 1:\n",
      "Objective function value = 0.5120636310255477\n",
      "Hyperparameters = \n",
      "{'dropout': 0.4641631336568098,\n",
      " 'fc_act_name': 'ReLU',\n",
      " 'learning_rate': 5.0980734177706554e-05,\n",
      " 'log_batch_size': 7,\n",
      " 'log_fc_hidden_size': 6,\n",
      " 'log_lstm_hidden_size': 7,\n",
      " 'lstm_act_name': 'Tanh',\n",
      " 'optimizer_name': 'Adam'}\n",
      "\n",
      "The best trial from tuning session 20250223132531419387:\n",
      "Trial number 0 with objective function value = 0.4108834130882461\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_hyperparameters.py -t {model_tuning_session_to_review.session_id} -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training\n",
    "For model hyperparameter tuning described in the previous section, we typically run ~50 epochs per fold (in the interest of reducing compute requirements). Based on the validation loss, AUC, and F1 curves from tuning trials, it appears that predictive performance could be improved by training for a larger number of epochs. We now run another round of Stratified K-fold cross-validation with our best set of parameters with a larger number of epochs.\n",
    "\n",
    "### 8.1 Notes on our Method\n",
    "* We are using \"flat\" cross-validation (as was done in previous studies on this dataset). This method computationally less expensive than nested cross-validation. Flat cross-validation has the potential to overestimate of model performance. In many cases the magnitude of overestimation is small. We also mitigate this effect by using a different set of (randomly generated) fold assignments than was used for hyperparameter tuning. \n",
    "* By selecting our hyperparameters based on the smaller number of epochs (100), we favor models that are faster to to train. It is possible that using a larger number of epochs in the tuning runs would have yielded a different (and better) set of \"best\" hyperparameters, but would also be computationally more expensive.\n",
    "\n",
    "### 8.2 Cross-Validation Training Settings\n",
    "Settings used during model training are specified in the `[model.cv_driver_settings]` section of the `config.toml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"model.cv_driver_settings\", {'collate_fn_name': 'x19m_collate_fn',\n",
    " 'epochs_per_fold': 1000,\n",
    " 'eval_interval': 10,\n",
    " 'fold_class_name': 'StratifiedKFold',\n",
    " 'kfold_random_seed': 20240807,\n",
    " 'num_folds': 5,\n",
    " 'single_fold_eval_fraction': 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Run Cross-Validation Training\n",
    "We can begin a training session by running the `train` module in the `model` sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [-t [MODEL_TUNING_ID]] [-r]\n",
      "                [--model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER]\n",
      "\n",
      "Runs cross-validation training using the best model hyperparameters from a\n",
      "particular model tuning session.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [MODEL_TUNING_ID], --model_tuning_id [MODEL_TUNING_ID]\n",
      "                        ID of model tuning session that hyperparameters are\n",
      "                        obtained from. Defaults to the most recently created\n",
      "                        session.\n",
      "  -r, --redirect        Redirect terminal output to log file\n",
      "  --model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER, -n MODEL_TUNING_TRIAL_NUMBER\n",
      "                        Optional integer specifying trial number (within\n",
      "                        study).Defaults to best trial from study.\n"
     ]
    }
   ],
   "source": [
    "!python model/train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20250223132531419387 \n"
     ]
    }
   ],
   "source": [
    "model_tuning_session_for_training_input = pipeline_info.get_stored_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new cross-validation training session 20250225120514809962.\n",
      "\n",
      "Will use best hyperparameters from model tuning session 20250223132531419387\n",
      "\n",
      "To monitor training in tensorboard, run the following command in another terminal:\n",
      "tensorboard --logdir /home/devspace/project/data/model/cross_validation/20250225120514809962/tensorboard --host=0.0.0.0\n",
      "Then go to http://localhost:6006/ in your browser.\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/model/training/20250225120514809962.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/model/training/20250225120514809962.log\n"
     ]
    }
   ],
   "source": [
    "!python model/train.py -t {model_tuning_session_for_training_input.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training is complete, store the session ID in our `PipelineInfo` object with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250225120514809962 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type=nh.SessionType.CV_TRAINING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Monitor Cross-Validation Progress in Tensorbard\n",
    "\n",
    "To view training curves in tensorboard, use Jupyter Lab to open a new terminal, and run:\n",
    "```\n",
    "tensorboard --logdir /home/devspace/project/data/model/tuning/<cross-validation-training-session-id>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "\n",
    "Then, go to http://localhost:6006 in your browser.\n",
    "\n",
    "This Tensorboard screenshot was taken at the end of a 5-fold, 1000 epoch per fold cross-validation run.\n",
    "![tensorboard_image](images/tensorboard_model_training_1000_epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Model Training Behavior: Continued Improvement at High Epoch Counts\n",
    "\n",
    "The above AUC and validation loss curves show continued (though diminishing) improvement in predictive performance during the entire 1000 epochs. The fact that we do not observe any sign of overfitting at such a large number of epochs is somewhat unusual. A likely cause of this behavior is the `WeightedRandomSampler` used in our training `DataLoaders`. Samples with our minority class label (`mortality = 1`) only represent ~15% of the total dataset. To deal with this imbalanced dataset, we oversample from the minority class and undersample from the majority class when creating batches of samples for training. In our current implementation, some samples from the majority class go unseen by the `StandardModelTrainer` for a large number of epochs. The number of unseen samples slowly dwindles (and the amount of information available for training slowly increases), even at very high epoch counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Summarize Model Training Results\n",
    "\n",
    "We can run the `model` sub-package's `view_model_training_summary` module to summarize each fold's best-performing checkpoint as well as the means and standard deviations of performance metrics across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20250225120514809962 \n"
     ]
    }
   ],
   "source": [
    "cv_training_id_for_summary = pipeline_info.get_stored_session(session_type=nh.SessionType.CV_TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: view_model_training_summary.py [-h] [-t [CV_TRAINING_ID]]\n",
      "\n",
      "Displays summary of model training session\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [CV_TRAINING_ID], --cv_training_id [CV_TRAINING_ID]\n",
      "                        ID of cross validation training session to summarize.\n",
      "                        Defaults to most recently created session\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_training_summary.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Cross Validation Training Session 20250225120514809962\n",
      "\n",
      "Best Performing Checkpoints by Fold\n",
      "                          0           1            2           3           4\n",
      "fold               0.000000    1.000000     2.000000    3.000000    4.000000\n",
      "epoch            980.000000  980.000000  1000.000000  850.000000  970.000000\n",
      "train_loss         0.339000    0.343377     0.343347    0.345060    0.347877\n",
      "validation_loss    0.336766    0.339939     0.340059    0.342779    0.344129\n",
      "auc                0.976525    0.971363     0.972433    0.969043    0.968571\n",
      "accuracy           0.976474    0.973302     0.973105    0.970297    0.969107\n",
      "f1                 0.975886    0.972677     0.972728    0.969886    0.968285\n",
      "precision          0.987187    0.990155     0.988223    0.989677    0.988503\n",
      "recall             0.964841    0.955805     0.957712    0.950870    0.948876\n",
      "\n",
      "Performance Metrics Means and Standard Deviations\n",
      "                     mean       std\n",
      "train_loss       0.343732  0.003225\n",
      "validation_loss  0.340734  0.002852\n",
      "auc              0.971587  0.003191\n",
      "accuracy         0.972457  0.002879\n",
      "f1               0.971892  0.002928\n",
      "precision        0.988749  0.001185\n",
      "recall           0.955621  0.006274\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_training_summary.py -t {cv_training_id_for_summary.session_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7 Comparing Training Results with Prior Studies' Predictive Models\n",
    "\n",
    "The table below compares the predictive performance of the LSTM model in this work with other LSTM-based models using the same dataset. The current model shows the best predictive performance among all models in the table based on AUC and F1 scores. \n",
    "\n",
    "\n",
    "| # | Authors     | Model                   | Input Features                                 | AUC             | F1              | Precision       | Recall          |\n",
    "|---|-------------|-------------------------|------------------------------------------------|-----------------|-----------------|-----------------|-----------------|\n",
    "|1  | Sun et al.  | LSTM-128 + FC-32 + FC-2 | [13 labs, 6 vitals] x 48 hr                    | 0.9094 (0.0053) | 0.5429 (0.0194) | 0.4100 (0.0272) | 0.8071 (0.0269) |\n",
    "|2  | Tang et al. | LSTM-256 + FC-2         | [13 labs, 6 vitals] x 48 hr + demographic data | 0.949 (0.003)   | 0.623 (0.012)   | -               | -               |\n",
    "|3  | Tang et al. | CNN + LSTM-256 + FC-2   | [13 labs, 6 vitals] x 48 hr + demographic data | 0.940 (0.0071)  | 0.633 (0.031)   | -               | -               |\n",
    "|4  | Tang et al. | CNN + LSTM-256 + FC-2   | [13 labs, 6 vitals] x 48 hr                    | 0.933 (0.006)   | 0.587 (0.025)   | -               | -               |\n",
    "|5  | Tang et al. | LSTM-256 + FC-2         | [13 labs, 6 vitals] x 48 hr                    | 0.907 (0.006)   | 0.526 (0.013)   | -               | -               |\n",
    "|6  | This work   | LSTM-128 + FC-16 + FC-2 | [13 labs, 6 vitals] x 48 hr                    | 0.9657 (0.0035) | 0.9669 (0.0038) | 0.9888 (0.0009) | 0.9459 (0.0072) |\n",
    "\n",
    "> **Notes**\n",
    "> - The values for the current study were taken from an earlier run of project code and are not \"live-populated\" when running this notebook.\n",
    "> - LSTM-X indicates an LSTM with X hidden layers.\n",
    "> - FC-X indicates a fully connected layer with an output size of X.\n",
    "> - All LSTMs are bidirectional.\n",
    "> - The demographic data used in studies #2 and #3 was obtained from MIMIC-III.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Attack Hyperparameter Tuning\n",
    "\n",
    "Before running an attack on the entire dataset, we tune attack hyperparameters with help from `optuna`. Our approach here is not as rigourous as the one we used for predictive model tuning. We use only a fraction of the total dataset for tuning, and do not perform cross-validation.\n",
    "\n",
    "## 9.1 Set ID of Training ID to Use for Attack Tuning\n",
    "\n",
    "For now, we will use the same training session that we summarized in Section 8.6, but this can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20250225120514809962'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_training_id_for_attack_tuning = cv_training_id_for_summary\n",
    "cv_training_id_for_attack_tuning.session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Attack Hyperparameter Tuning Config Settings\n",
    "\n",
    "Settings that affect attack hyperparameter tuning are under `[attack.tuning.ranges]` and `[attack.tuner_driver_settings]`in the `config.toml`. We can view the current values of these settings using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"attack.tuning.ranges\", {'kappa': [0.0, 2.0],\n",
    " 'lambda_1': [1e-07, 1.0],\n",
    " 'learning_rate': [1e-05, 1.0],\n",
    " 'log_batch_size': [5, 7],\n",
    " 'optimizer_options': ['Adam', 'RMSprop', 'SGD']})\n",
    "\n",
    "nh.set_config_value(\"attack.tuner_driver_settings\", {'db_env_var_name': 'ATTACK_TUNING_DB_NAME',\n",
    " 'num_trials': 75,\n",
    " 'epochs_per_batch': 1000,\n",
    " 'max_num_samples': 1028,\n",
    " 'sample_selection_seed': 2023,\n",
    " 'pruner_name': 'MedianPruner',\n",
    " 'sampler_name': 'TPESampler',\n",
    " 'objective_name': 'sparse_small',\n",
    " 'max_perts': 0,\n",
    " 'attack_misclassified_samples': False,\n",
    " 'objective_extra_kwargs': {},\n",
    " 'pruner_kwargs': {},\n",
    " 'sampler_kwargs': {}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `max_num_samples` parameter specifies the number of samples to be considered for attack. However, samples that are misclassified by the target model are not attacked, so the actual number of samples used for tuning will be slightly lower.\n",
    "\n",
    "### 9.2 Adversarial Example Quality Scores\n",
    "\n",
    "Each trial in an attack tuning study runs `epochs_per_batch` attack iterations on each of the selected samples. Then, an adversarial example quality score is calculated for the lowest loss adversarial example each sample that has at least one associated adversarial example. A trial's score is the sum of these example quality scores. The `objective_name` parameter specifies the objective function used to calculate the quality scores.\n",
    " \n",
    " The following table summarizes how each of the available objective functions calculates the quality score of a single adversarial perturbation matrix $P_{adv}$.\n",
    "\n",
    "| Objective               | Example Quality Score Formula                       |\n",
    "| ------------------------| ----------------------------------------------------|\n",
    "| sparsity                | $1 - f_{nonzero}$                                   |\n",
    "| max_num_nonzero_perts   | $if\\; n_{nonzero} < n_{critical}: 1, otherwise: 0$  |\n",
    "| sparse_small            | $sparsity\\;/\\;\\|\\|P_{adv}\\|\\|_1$                    |\n",
    "| sparse_small_max        | $sparsity\\;/\\ max(\\|P_{adv}\\|)$                     |\n",
    "\n",
    "where:\n",
    "- $n_{nonzero}$ is the number of non-zero elements in $P_{adv}$\n",
    "- $f_{nonzero}$ is the fraction of non-zero elements\n",
    "- $\\|P_{adv}\\|_1$ is the L1 norm\n",
    "- $|P_{adv}|$ is the element-wise absolute value.\n",
    "\n",
    "### 9.3 Tune Attack with `sparse_small` Objective\n",
    "\n",
    "Although, `attack.tuner_driver_settings.objective_name` should already be set to `sparse_small_max`, let's set it again to be sure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"attack.tuner_driver_settings.objective_name\", \"sparse_small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start a new attack hyperparameter tuning session with the `attack` sub-package's `tune_attack_new` module. If a tuning session is stopped early (via CTRL-C or the notebook Stop button), data from completed trials will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune_attack_new.py [-h] [-t [CV_TRAINING_ID]] [-r]\n",
      "\n",
      "Starts a new study for tuning attack hyperparameters.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [CV_TRAINING_ID], --cv_training_id [CV_TRAINING_ID]\n",
      "                        ID of cross validation tuning session providing\n",
      "                        trained model for attack.\n",
      "  -r, --redirect        Redirect terminal output to log file\n"
     ]
    }
   ],
   "source": [
    "!python attack/tune_attack_new.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new Attack Hyperparameter Tuning session 20250304150536178383.\n",
      "Using trained model from CV training session ID 20250225120514809962 as the attack target.\n",
      "\n",
      "Attack tuner driver settings:\n",
      "{'db_env_var_name': 'ATTACK_TUNING_DB_NAME',\n",
      " 'epochs_per_batch': 1000,\n",
      " 'max_num_samples': 1028,\n",
      " 'max_perts': 0,\n",
      " 'num_trials': 75,\n",
      " 'objective_name': 'sparse_small',\n",
      " 'pruner_kwargs': {},\n",
      " 'pruner_name': 'MedianPruner',\n",
      " 'sample_selection_seed': 2023,\n",
      " 'sampler_kwargs': {},\n",
      " 'sampler_name': 'TPESampler'}\n",
      "\n",
      "\u001b[32m[I 2025-03-04 15:05:51,484]\u001b[0m A new study created in RDB with name: attack_tuning_20250304150536178383\u001b[0m\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/attack/tuning/20250304150536178383.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/attack/tuning/20250304150536178383.log\n"
     ]
    }
   ],
   "source": [
    "!python attack/tune_attack_new.py -t {cv_training_id_for_attack_tuning.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When attack tuning is complete, store the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250305184453643583 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type=nh.SessionType.ATTACK_TUNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Tune Attack with `sparse_small_max` Objective\n",
    "\n",
    "We change the objective name in our `config.toml` using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"attack.tuner_driver_settings.objective_name\", \"sparse_small_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new Attack Hyperparameter Tuning session 20250305184453643583.\n",
      "Using trained model from CV training session ID 20250225120514809962 as the attack target.\n",
      "\n",
      "Attack tuner driver settings:\n",
      "{'db_env_var_name': 'ATTACK_TUNING_DB_NAME',\n",
      " 'epochs_per_batch': 1000,\n",
      " 'max_num_samples': 1028,\n",
      " 'max_perts': 0,\n",
      " 'num_trials': 75,\n",
      " 'objective_name': 'sparse_small_max',\n",
      " 'pruner_kwargs': {},\n",
      " 'pruner_name': 'MedianPruner',\n",
      " 'sample_selection_seed': 2023,\n",
      " 'sampler_kwargs': {},\n",
      " 'sampler_name': 'TPESampler'}\n",
      "\n",
      "\u001b[32m[I 2025-03-05 18:45:09,148]\u001b[0m A new study created in RDB with name: attack_tuning_20250305184453643583\u001b[0m\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/attack/tuning/20250305184453643583.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/attack/tuning/20250305184453643583.log\n"
     ]
    }
   ],
   "source": [
    "!python attack/tune_attack_new.py -t {cv_training_id_for_attack_tuning.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store this attack tuning session once it is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_info.store_session(session_type=nh.SessionType.ATTACK_TUNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 9.5 Resuming an Existing Attack Tuning Session\n",
    "The `tune_attack_resume` module can be used to run more trials as part of an existing attack tuning study. If we are resuming the most recently created attack tuning study, we can set `custom_attack_tuning_id_to_resume` in the next cell to `None`. Otherwise, set it to the ID of the session we want to resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20250223131513840062': SessionInfo(session_type=<SessionType.DB_QUERIES: 1>, session_id='20250223131513840062', comment=None),\n",
       " '20250223131653849429': SessionInfo(session_type=<SessionType.PREPROCESS: 2>, session_id='20250223131653849429', comment=None),\n",
       " '20250223132531419387': SessionInfo(session_type=<SessionType.MODEL_TUNING: 3>, session_id='20250223132531419387', comment=None),\n",
       " '20250225120514809962': SessionInfo(session_type=<SessionType.CV_TRAINING: 4>, session_id='20250225120514809962', comment=None)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_info.sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set this to ID of session to resume (OK to leave as None if resuming most recently created study)\n",
    "custom_attack_tuning_id_to_resume = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_tuning_id_to_resume = get_session_id(custom_attack_tuning_id_to_resume, \"attack.tuner_driver.output_dir\")\n",
    "attack_tuning_id_to_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/tune_attack_resume.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/tune_attack_resume.py -t {attack_tuning_id_to_resume} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Attacking the Full Dataset with Tuned Attack Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_READER.get_value(\"attack.driver_settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_MODIFIER.set(\"attack.driver_settings\", {'epochs_per_batch': 1000,\n",
    " 'max_num_samples': 40000,\n",
    " 'sample_selection_seed': 2023,\n",
    " 'attack_misclassified_samples': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Attack Using Best Hyperparameters from `sparse_small_max` Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/attack.py -t {sparse_small_max_attack_tuning_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Attack Using Best Hyperparameters from `sparse_small` Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/attack.py -t {sparse_small_attack_tuning_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id=\"ref_01\"></a>1. [Sun, M., Tang, F., Yi, J., Wang, F. and Zhou, J., 2018, July. Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining* (pp. 793-801).](https://dl.acm.org/doi/10.1145/3219819.3219909)\n",
    "\n",
    "<a id=\"ref_02\"></a>2. [Tang, F., Xiao, C., Wang, F. and Zhou, J., 2018. Predictive modeling in urgent care: a comparative study of machine learning approaches. *Jamia Open*, *1*(1), pp.87-98.](https://academic.oup.com/jamiaopen/article/1/1/87/5032901)\n",
    "\n",
    "<a><a id=\"ref_03\"></a>3. [Johnson, A., Pollard, T., and Mark, R. (2016) 'MIMIC-III Clinical Database' (version 1.4), *PhysioNet*.](https://doi.org/10.13026/C2XW26) \n",
    "\n",
    "<a id=\"ref_04\"></a>4. [Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific Data, 3, 160035.](https://www.nature.com/articles/sdata201635)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
